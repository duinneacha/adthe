Automatically generated by Mendeley Desktop 1.19.4
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@misc{Raymond2003,
author = {Raymond, Eric Steven},
title = {{Basics of the Unix Philosophy}},
url = {http://www.catb.org/{~}esr/writings/taoup/html/ch01s06.html{\#}id2878339},
urldate = {2020-01-03},
year = {2003}
}
@article{Braiek2018,
abstract = {Recent advances in computing technologies and the availability of huge volumes of data have sparked a new machine learning (ML) revolution, where almost every day a new headline touts the demise of human experts by ML models on some task. Open source software development is rumoured to play a significant role in this revolution, with both academics and large corporations such as Google and Microsoft releasing their ML frameworks under an open source license. This paper takes a step back to examine and understand the role of open source development in modern ML, by examining the growth of the open source ML ecosystem on GitHub, its actors, and the adoption of frameworks over time. By mining LinkedIn and Google Scholar profiles, we also examine driving factors behind this growth (paid vs. voluntary contributors), as well as the major players who promote its democratization (companies vs. communities), and the composition of ML development teams (engineers vs. scientists). According to the technology adoption lifecycle, we find that ML is in between the stages of early adoption and early majority. Furthermore, companies are the main drivers behind open source ML, while the majority of development teams are hybrid teams comprising both engineers and professional scientists. The latter correspond to scientists employed by a company, and by far represent the most active profiles in the development of ML applications, which reflects the importance of a scientific background for the development of ML frameworks to complement coding skills. The large influence of cloud computing companies on the development of open source ML frameworks raises the risk of vendor lock-in. These frameworks, while open source, could be optimized for specific commercial cloud offerings.},
author = {Braiek, Houssem Ben and Khomh, Foutse and Adams, Bram},
doi = {10.1145/3196398.3196445},
file = {:D$\backslash$:/CIT/FYP/books/3196398.3196445.pdf:pdf},
isbn = {9781450357166},
issn = {02705257},
journal = {Proceedings - International Conference on Software Engineering},
keywords = {framework,machine learning,open source,technology adoption},
pages = {353--363},
title = {{The open-closed principle of modern machine learning frameworks}},
year = {2018}
}
@book{95979,
address = {Sebastopol, CA ;},
author = {Iliinsky, Noah P N and Steele, Julie},
publisher = {O'Reilly,},
title = {{Designing data visualizations /}}
}
@article{Djatna2015,
abstract = {Nowadays, Small and Medium Enterprises (SME), need tight requirements to increase the diffuse and adopt of information and communication technology (ITC), so that the digital gap between large and small enterprises as well as regional difference can be avoided. Digital business ecosystem (DBE) is centralized collaboration environment of the species as stakeholder communities within the business ecosystem. This paper describes to model the responsive supply chain through the analysis and design to answer the stakeholder's needs of information and decisions, and involve in managing product and perishable material as well. Therefore, the objectives of this research are to identify the component and process in systems analysis, to develop the design responsive supply chain system of pineapple multi product for SME. The benefits that can be obtained by digitalized information are cost efficiency and effectiveness of service time for SMEs, employees and consumers when it responds quickly to changes the information system, supply of raw materials, production facilities and inventory system. The research approach includes decomposition of process analysis by business process model notation (BPMN). Then quantitative modeling design deployed decision tree classifier method. The model consisted of structures, information system, mode transportation, raw material and finish good inventory. The last step is optimization of responsive model by cross platform drivers function. Computational results and managerial insights are provided. To show that substantial reduction in response time can achieved with minimal increase in total cost in the design of responsive supply chain.},
author = {Djatna, Taufik and Luthfiyanti, Rohmah},
doi = {10.1016/j.promfg.2015.11.026},
file = {:C$\backslash$:/Users/User/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Djatna, Luthfiyanti - 2015 - An Analysis and Design of Responsive Supply Chain for Pineapple Multi Products SME Based on Digital Busines.pdf:pdf},
isbn = {0000000000},
issn = {23519789},
journal = {Procedia Manufacturing},
keywords = {Analysis and Design,Communities Stakeholder,Digital Business Ecosystem (DBE),Pineapple Multi Product,Responsive Supply Chain},
number = {Iess},
pages = {155--162},
publisher = {Elsevier B.V.},
title = {{An Analysis and Design of Responsive Supply Chain for Pineapple Multi Products SME Based on Digital Business Ecosystem (DBE)}},
url = {http://dx.doi.org/10.1016/j.promfg.2015.11.026},
volume = {4},
year = {2015}
}
@article{Clements2013,
author = {Clements, Paul and Kazman, Rick and Klein, Mark and Boehm, Barry},
file = {:D$\backslash$:/CIT/FYP/books/paul clements Evaluating a Software Architecture.pdf:pdf},
pages = {1--17},
title = {{Evaluating a Software Architecture}},
year = {2013}
}
@article{Noback2018,
abstract = {This is the fourth of my Engineering Notebook columns for The C++ Report . The articles that appear in this column focus on the use of C++ and OOD, and address issues of soft- ware engineering. I strive for articles that are pragmatic and directly useful to the software engineer in the In these articles I make use of Booch's and Used Base Class Rumbaugh's new unified Modeling Langage (UML Version 0.8) for document- ing object oriented designs. The sidebar provides a brief lexicon of this nota- tion.},
author = {Noback, Matthias and Noback, Matthias},
doi = {10.1007/978-1-4842-4119-6_4},
file = {:D$\backslash$:/CIT/FYP/books/896isp.pdf:pdf},
journal = {Principles of Package Design},
number = {c},
pages = {55--66},
title = {{The Interface Segregation Principle}},
year = {2018}
}
@article{Leder2015,
abstract = {The present study sought to examine the underpinnings of impaired strategic decision-making under stress. In contrast to previous laboratory-based research, we conducted a quasi-experiment in a real life stress situation. Specifically, we used the beauty contest game and compared the performance of a group of participants who were exposed to a real-life stressor (waiting to attend an exam at a university class) with a control group of participants who were not exposed to stress (waiting to attend a regular lecture at a university class). Furthermore, about half of the participants were instructed to write down what they believed another participant had assumed the average number in the beauty contest game to be and which target number she (or he) had chosen accordingly. The results showed that stress impaired strategic reasoning in the beauty contest game. Importantly, even when only including participants who understood the rules of the game in the analyses, stress still increased the numbers chosen in the beauty contest. Furthermore, we found that participants in the stress condition were significantly less likely to base their chosen number on their belief about other players' choices. Hence, stress not only impairs understanding of the math behind the beauty contest game but also the degree of strategizing per se.},
author = {Leder, Johannes and H{\"{a}}usser, Jan Alexander and Mojzisch, Andreas},
doi = {10.1016/j.joep.2015.05.006},
file = {:C$\backslash$:/Users/User/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Leder, H{\"{a}}usser, Mojzisch - 2015 - Exploring the underpinnings of impaired strategic decision-making under stress.pdf:pdf},
issn = {01674870},
journal = {Journal of Economic Psychology},
keywords = {Beauty contest game,Decision-making,Strategic behavior,Stress},
pages = {133--140},
publisher = {Elsevier B.V.},
title = {{Exploring the underpinnings of impaired strategic decision-making under stress}},
url = {http://dx.doi.org/10.1016/j.joep.2015.05.006},
volume = {49},
year = {2015}
}
@article{Baniassad2018,
abstract = {The Liskov Substitution Principle states, among other constraints, that a subtype is not substitutable for its super type if it strengthens its operations' preconditions, or weakens its operations' postconditions. We found that students in two subsequent courses had trouble remembering these rules. Their major stumbling block appeared to be recalling which condition (pre-or post-) could be strengthened and which could be weakened. We developed a simple visual reminder to help: A method is happy if it is substitutable-A smile is wider at the top than at the bottom, suggesting weaker/looser/wider preconditions, and stronger/tighter/narrower post conditions.; A method is sad if it isn't substitutable-a frown is narrower at the top, suggesting stronger/tighter/narrower preconditions, and wider at the bottom, suggesting weaker/looser/wider postconditions. Though the technique is far from perfect, we found that it allowed students to move on to the more interesting design questions around the LSP.},
author = {Baniassad, Elisa},
doi = {10.1145/3183377.3183392},
file = {:D$\backslash$:/CIT/FYP/books/08445178.pdf:pdf},
isbn = {9781450356602},
issn = {02705257},
journal = {Proceedings - International Conference on Software Engineering},
keywords = {Software engineering education},
pages = {17--20},
publisher = {ACM},
title = {{Making the Liskov substitution principle happy and sad}},
year = {2018}
}
@article{Kanwal2017,
abstract = {The linguist George Kingsley Zipf made a now classic observation about the relationship between a word's length and its frequency; the more frequent a word is, the shorter it tends to be. He claimed that this “Law of Abbreviation” is a universal structural property of language. The Law of Abbreviation has since been documented in a wide range of human languages, and extended to animal communication systems and even computer programming languages. Zipf hypothesised that this universal design feature arises as a result of individuals optimising form-meaning mappings under competing pressures to communicate accurately but also efficiently—his famous Principle of Least Effort. In this study, we use a miniature artificial language learning paradigm to provide direct experimental evidence for this explanatory hypothesis. We show that language users optimise form-meaning mappings only when pressures for accuracy and efficiency both operate during a communicative task, supporting Zipf's conjecture that the Principle of Least Effort can explain this universal feature of word length distributions.},
author = {Kanwal, Jasmeen and Smith, Kenny and Culbertson, Jennifer and Kirby, Simon},
doi = {10.1016/j.cognition.2017.05.001},
file = {:D$\backslash$:/CIT/FYP/books/1-s2.0-S0010027717301166-main.pdf:pdf},
issn = {18737838},
journal = {Cognition},
keywords = {Artificial language learning,Efficient communication,Information theory,Language universals,Principle of Least Effort,Zipf's Law of Abbreviation},
pages = {45--52},
publisher = {Elsevier B.V.},
title = {{Zipf's Law of Abbreviation and the Principle of Least Effort: Language users optimise a miniature lexicon for efficient communication}},
url = {http://dx.doi.org/10.1016/j.cognition.2017.05.001},
volume = {165},
year = {2017}
}
@article{Naldi2016,
abstract = {Companies typically select those projects that maximize their profit as the primary criterion, within the limited budget at their disposal. This criterion may lead to some company departments getting an exceedingly large share of the overall budget and induce a negative perception of unfairness among the less favourite ones. We investigate how profit optimization can be sought after while achieving the desired level of fairness at the same time. Adopting a maximin approach to fairness and using an Integer Linear Programming solver, we show that a linear trade-off is possible, since fairness and profit exhibit a nearly perfect linear anticorrelation. Fairness can be improved by even a relatively small reduction of profit, especially in large companies (i.e., managing a large number of projects).},
author = {Naldi, Maurizio and Nicosia, Gaia and Pacifici, Andrea and Pferschy, Ulrich},
doi = {10.1016/j.procs.2016.09.162},
file = {:C$\backslash$:/Users/User/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Naldi et al. - 2016 - Maximin Fairness-profit Tradeoff in Project Budget Allocation.pdf:pdf},
issn = {18770509},
journal = {Procedia Computer Science},
keywords = {Budget allocation,Fairness,Multi-project management,Project Portfolio},
pages = {313--320},
publisher = {The Author(s)},
title = {{Maximin Fairness-profit Tradeoff in Project Budget Allocation}},
url = {http://dx.doi.org/10.1016/j.procs.2016.09.162},
volume = {100},
year = {2016}
}
@article{Nakajima2011,
abstract = {Self-adaptive systems, changing their functional behavior at runtime, provide desired a level of flexibility. Although various runtime frameworks have been studied, they tend to rely on a particular architecture. It is inadequate to study the characteristics of self-adaptive systems. This paper presents an abstract, declarative framework for them and relates it to an adaptive PHP-based Web application architecture, which takes a model-based adaptation approach. The formalism can be a basis for understanding the distinctive roles of the model information and runtime mechanism. {\textcopyright} 2011 IEEE.},
author = {Nakajima, Shin},
doi = {10.1109/APSEC.2011.14},
file = {:D$\backslash$:/CIT/FYP/books/06130688.pdf:pdf},
isbn = {9780769546094},
issn = {15301362},
journal = {Proceedings - Asia-Pacific Software Engineering Conference, APSEC},
keywords = {Feature interferences,Open systems,Requirements,Self-adaptive systems},
pages = {203--210},
publisher = {IEEE},
title = {{An architecture of dynamically adaptive PHP-based web applications}},
year = {2011}
}
@article{Barricelli2019b,
abstract = {End-User Development (EUD), End-Programming (EUP) and End-User Software Engineering (EUSE) are three related research fields that study methods and techniques for empowering end users to modify and create digital artifacts. This paper presents a systematic mapping study aimed at identifying and classifying scientific literature about EUD, EUP and EUSE in the time range January 2000–May 2017. We selected 165 papers found through a manual selection of papers from specific conferences, journal special issues, and books, integrated with an automatic search on the most important digital libraries. The answer to our research question was built through a classification of the selected papers on seven dimensions: type of approach, interaction technique, phase in which the approach is adopted, application domain, target use, class of users, and type of evaluation. Our findings suggest that EUD, EUP and EUSE are active research topics not only in Human–Computer Interaction, but also in other research communities. However, little cross-fertilization exists among the three themes, as well as unifying frameworks and approaches for guiding novice designers and practitioners. Other findings highlight trends and gaps related to the analysis' dimensions, which have implications on the design of future tools and suggest open issues for further investigations.},
author = {Barricelli, Barbara Rita and Cassano, Fabio and Fogli, Daniela and Piccinno, Antonio},
doi = {10.1016/j.jss.2018.11.041},
file = {:D$\backslash$:/CIT/FYP/books/1-s2.0-S0164121218302577-main.pdf:pdf},
issn = {01641212},
journal = {Journal of Systems and Software},
keywords = {End-user development,End-user programming,End-user software engineering,Systematic mapping study},
pages = {101--137},
publisher = {Elsevier Inc.},
title = {{End-user development, end-user programming and end-user software engineering: A systematic mapping study}},
url = {https://doi.org/10.1016/j.jss.2018.11.041},
volume = {149},
year = {2019}
}
@article{Murthy2018,
abstract = {Software components are still considered the weakest link when it comes to addressing reliability of a system. We argue that a systematic application of Bertrand Meyer's design by contract methodology improves reliability quite significantly. In the perspective of design by contract methodology, reliability is viewed as correctness and robustness. The concept of Reliability by Construction is dealt with in detail. Process steps to introduce or integrate design by contract methodology into existing SDLC of a product or system are discussed. The notion of sufficiently strong contracts is dealt with along with their advantages in defect prevention. Composition of function calls or services and the properties that contract specifications of successive functions(calls) need satisfy are stated. The process of contract refinement during successive phases of SDLC is discussed. Contract specification rules in the presence of inheritance in object-oriented programs are also discussed. Finally, we argue that design by contract methodology is a step towards zero-defect programming.},
author = {Murthy, P. V.R.},
doi = {10.1109/ICACCI.2018.8554801},
file = {:D$\backslash$:/CIT/FYP/books/08554801.pdf:pdf},
isbn = {9781538653142},
journal = {2018 International Conference on Advances in Computing, Communications and Informatics, ICACCI 2018},
keywords = {Contract,Correctness,Reliability,Robustness},
pages = {482--488},
publisher = {IEEE},
title = {{Design by Contract Methodology}},
year = {2018}
}
@article{VisualizationOverview,
author = {Sahay, Amar.},
file = {:D$\backslash$:/CIT/FYP/books/Data{\_}Visualization{\_}Volume{\_}II{\_}Uncovering{\_}the{\_}Hidden...{\_}----{\_}(CHAPTER{\_}1{\_}Overview{\_}and{\_}Data{\_}Visualization).pdf:pdf},
keywords = {Amar.,Sahay},
pages = {1--10},
title = {{Data Visualization Volume II; Overview and Data Visualization}},
url = {https://ebookcentral.proquest.com/lib/cit-ebooks/detail.action?docID=4819435},
volume = {II}
}
@article{Agnihotri2017,
abstract = {Despite the growing recognition of the critical role of post-sale service on the salesperson-customer relationship, few studies have explored how salesperson service behaviors (SSB) are enhanced through tools such as sales-based customer relationship management (CRM) technology and social media. Using dyadic salesperson-customer data within a business-to-business context, this study analyzes the direct effects of sales-based CRM technology on the behaviors of diligence, information communication, inducements, empathy and sportsmanship. Additionally, the study examines the interactive effects of sales-based CRM technology and social media on these behaviors. The results indicate that sales-based CRM technology has a positive influence on SSBs and that salespeople using CRM technology in conjunction with social media are more likely to exhibit higher levels of SSBs than their counterparts with low social media technology use.},
author = {Agnihotri, Raj and Trainor, Kevin J. and Itani, Omar S. and Rodriguez, Michael},
doi = {10.1016/j.jbusres.2017.08.021},
file = {:C$\backslash$:/Users/User/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Agnihotri et al. - 2017 - Examining the role of sales-based CRM technology and social media use on post-sale service behaviors in India.pdf:pdf},
issn = {01482963},
journal = {Journal of Business Research},
keywords = {CRM,Salesperson service behaviors,Social CRM,Social media,Social selling},
month = {dec},
pages = {144--154},
publisher = {Elsevier Inc.},
title = {{Examining the role of sales-based CRM technology and social media use on post-sale service behaviors in India}},
volume = {81},
year = {2017}
}
@article{Zilinskas2006,
abstract = {Process optimisation is often a multi-criteria problem. Combined with the use of nonlinear models, generating a Pareto front can be difficult to achieve reliably. This paper describes the use of high-dimensional data analysis and visualisation techniques as the basis for a multi-step procedure for generating a Pareto front for a two criteria problem. A case study in process design is used to illustrate the procedure. The results show that the use of data analysis and visualisation can help gain insight into the Pareto optimal solutions or confirm the insight the engineer already has. {\textcopyright} 2006 Elsevier Ltd. All rights reserved.},
author = {{\v{Z}}ilinskas, Antanas and Fraga, Eric S. and Mackute, Ausra},
doi = {10.1016/j.compchemeng.2006.02.003},
file = {:D$\backslash$:/CIT/FYP/books/j.compchemeng.2006.02.003.pdf:pdf},
issn = {00981354},
journal = {Computers and Chemical Engineering},
keywords = {Data analysis,Nonlinear optimization,Pareto sets,Visualisation},
number = {6-7},
pages = {1061--1071},
title = {{Data analysis and visualisation for robust multi-criteria process optimisation}},
volume = {30},
year = {2006}
}
@inproceedings{Dombrowski2014,
abstract = {Lean leadership could be the missing link between toolbox lean and a sustainable continuously improving organization. More and more enterprises realize that they have so far basically focused on the visible parts of lean production systems. Although process optimization with the various methods like kanban, 5S, SMED, FIFO and many more is very effective to achieve short term improvements, after a few years, the lean programs of many enterprises do not meet the expectations anymore. The common approach can be explained by using the 4P Model. It consists of 4 levels that are all necessary for a sustainable lean implementation. The levels are: philosophy (long-Term thinking), process (eliminate waste), people and partner (respect, challenge and grow them) and problem solving (CIP and learning). All these terms are wellknown. However, most enterprises merely focus on process. Eliminating waste in all processes has been preponderantly adopted, whereas the other 3Ps, the "invisible" parts of lean, are less easy to adopt but equally important for the sustainable implementation. Lean leadership addresses all 4Ps and provides a methodical system for the sustainable implementation and continuous improvement of lean production systems. It describes the cooperation of employees and leaders in their mutual striving for perfection. By now, many authors have identified the need for a lean leadership but only few holistic concepts exist. Especially lower and middle management lacks some clear advices and rules for lean leadership implementation. Therefore, some indicators for successful lean leadership were deduced from literature, study results, and practical experiences of lean implementation. The indicators were found in advices given on successful lean implementations, but particularly in mistakes and shortcomings. After reformulating the indicators into requirements for leaders, they were assigned to the five principles improvement culture, self-development, qualification, gemba, and hoshin kanri. These requirements shall help executives in realizing lean leadership. {\textcopyright} 2014 Elsevier B.V.},
author = {Dombrowski, U. and Mielke, T.},
booktitle = {Procedia CIRP},
doi = {10.1016/j.procir.2014.01.146},
file = {:C$\backslash$:/Users/User/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Dombrowski, Mielke - 2014 - Lean leadership -15 rules for a sustainable lean implementation.pdf:pdf},
issn = {22128271},
keywords = {Beyond lean,Continuous improvement,Lean leadership,Lean production},
pages = {565--570},
publisher = {Elsevier B.V.},
title = {{Lean leadership -15 rules for a sustainable lean implementation}},
volume = {17},
year = {2014}
}
@article{VandenBroucke2018,
abstract = {Congratulations! By picking up this book, you've set the first steps into the exciting world of web scraping. First of all, we want to thank you, the reader, for choosing this guide to accompany you on this journey},
author = {vanden Broucke, Seppe and Baesens, Bart},
doi = {10.1007/978-1-4842-3582-9},
file = {:D$\backslash$:/CIT/FYP/books/978-1-4842-3582-9{\_}6.pdf:pdf},
isbn = {9781484235829},
journal = {Practical Web Scraping for Data Science},
pages = {155--172},
title = {{Practical Web Scraping for Data Science}},
year = {2018}
}
@article{Matsumoto2017,
abstract = {In order to verify the correctness of functional requirements, we have been developing a verification method of the correctness of functional requirements specification using the Requirements Frame model. In this paper, we introduce a verification method of non-functional requirements specification, especially time-response requirements and usability requirements written with a natural language. We establish a verification method by extending the Requirements Frame model. We have also developed a prototype system based on the method using Java. The extended Requirements Frame model and the verification method will be illustrated with examples.},
author = {Matsumoto, Yuuma and Shirai, Sayaka and Ohnishi, Atsushi},
doi = {10.1016/j.procs.2017.08.006},
file = {:C$\backslash$:/Users/User/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Matsumoto, Shirai, Ohnishi - 2017 - A Method for Verifying Non-Functional Requirements.pdf:pdf},
issn = {18770509},
journal = {Procedia Computer Science},
keywords = {Non-functional requirements,Requirements frame,Time-Response requirements,Usability requirements,Verification of non-functional requirements},
pages = {157--166},
publisher = {Elsevier B.V.},
title = {{A Method for Verifying Non-Functional Requirements}},
url = {http://dx.doi.org/10.1016/j.procs.2017.08.006},
volume = {112},
year = {2017}
}
@article{Glez-Pena2013a,
abstract = {Web services are the de facto standard in biomedical data integration. However, there are data integration scenarios that cannot be fully covered by Web services. A number of Web databases and tools do not support Web services, and existing Web services do not cover for all possible user data demands. As a consequence,Web data scraping, one of the oldest techniques for extracting Web contents, is still in position to offer a valid and valuable service to a wide range of bioinformatics applications, ranging from simple extraction robots to online meta-servers.This article reviews existing scraping frameworks and tools, identifying their strengths and limitations in terms of extraction capabilities. The main focus is set on showing how straightforward it is today to set up a data scraping pipeline, with minimal programming effort, and answer a number of practical needs. For exemplification purposes, we introduce a biomedical data extraction scenario where the desired data sources, well-known in clinical microbiology and similar domains, do not offer programmatic interfaces yet. Moreover, we describe the operation of WhichGenes and PathJam, two bioinformatics meta-servers that use scraping as means to cope with gene set enrichment analysis.},
author = {Glez-Pe{\~{n}}a, Daniel and Louren{\c{c}}o, An{\'{a}}lia and L{\'{o}}pez-Fern{\'{a}}ndez, Hugo and Reboiro-Jato, Miguel and Fdez-Riverola, Florentino},
doi = {10.1093/bib/bbt026},
file = {:D$\backslash$:/CIT/FYP/books/ContentServer.pdf:pdf},
issn = {14774054},
journal = {Briefings in Bioinformatics},
keywords = {Data integration,Database interfaces,Interoperability,Web scraping},
number = {5},
pages = {788--797},
title = {{Web scraping technologies in an API world}},
volume = {15},
year = {2013}
}
@article{DeMorais2017,
abstract = {Adaptability is the yield response of cassava genotypes to environmental improvement, and stability is the predictability of this response to variations. The objective of this study was to evaluate the yield stability and adaptability of cassava varieties and clones using the AMMI (Additive Main Effects and Multiplicative Interaction) methodology and auxiliary tools as supplementary genotype and environment. The responses of 24 cassava genotypes were evaluated in three environments located in the state of Alagoas, Brazil, in randomized blocks design, with 24 treatments and three replications. The effects of genotype and genotype x environment interactions significantly influenced yield. Genotypes differed regarding the adaptability and stability of yield response, and the varieties Cria Menino and Preta do Araripe were considered ideal genotypes due to high adaptability and yield stability. Among the three tested environments, Limoeiro de Anadia was the best since it presented high yield, phenotypically stable genotypes for cassava breeding programs.},
author = {de Morais, Lizz Kezzy and Santiago, Ant{\^{o}}nio Dias and Cavalcante, Manoel Henrique Bonfim},
doi = {10.1590/1984-70332017v17n4a55},
file = {:D$\backslash$:/CIT/FYP/books/0135974445{\_}TOC.pdf:pdf},
issn = {19847033},
journal = {Crop Breeding and Applied Biotechnology},
keywords = {Environment interaction,Genotype,Ideal environment,Ideal genotype,Manihot esculenta},
number = {4},
pages = {366--372},
title = {{Phenotypic stability in cassava estimated by the AMMI analysis with supplementary genotypes}},
volume = {17},
year = {2017}
}
@article{Kanakis2019,
abstract = {Most engineering tools do not provide much support for collaborating teams and today's engineering knowledge repositories lack flexibility and are limited. Engineering teams have different needs and their team members have different preferences on how and when to collaborate. These needs may depend on the individual work style, the role an engineer has, and the tasks they have to perform within the collaborating group. However, individual collaboration is insufficient and engineers need to collaborate in groups. This work presents a collaboration framework for collaborating groups capable of providing synchronous and asynchronous mode of collaboration. Additionally, our approach enables engineers to mix these collaboration modes to meet the preferences of individual group members. We evaluate the scalability of this framework using four real life large collaboration projects. These projects were found from GitHub and they were under active development by the time of evaluation. We have tested our approach creating groups of different sizes for each project. The results showed that our approach scales to support every case for the groups created. Additionally, we scouted the literature and discovered studies that support the usefulness of different groups with collaboration styles.},
author = {Kanakis, Georgios and Fischer, Stefan and Khelladi, Djamel Eddine and Egyed, Alexander},
doi = {10.1109/ICGSE.2019.00033},
file = {:D$\backslash$:/CIT/FYP/books/08807504.pdf:pdf},
isbn = {9781538691960},
journal = {Proceedings - 2019 ACM/IEEE 14th International Conference on Global Software Engineering, ICGSE 2019},
keywords = {change propagation,collaborating groups,collaboration,software engineering},
pages = {129--138},
publisher = {IEEE},
title = {{Supporting A Flexible Grouping Mechanism for Collaborating Engineering Teams}},
year = {2019}
}
@article{Sneed1995,
abstract = {How can you know if reengineering is cost-effective? If it is preferable to new development? Or to maintaining the status quo? The author proposes a way to quantify the costs and prove the benefits of reengineering over other alternatives and offers some advice on contracting a reengineering project. {\textcopyright} 1995, IEEE. All rights reserved.},
author = {Sneed, Harry M.},
doi = {10.1109/52.363168},
file = {:C$\backslash$:/Users/User/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Sneed - 1995 - Planning the Reengineering of Legacy Systems.pdf:pdf},
issn = {07407459},
journal = {IEEE Software},
number = {1},
pages = {24--34},
title = {{Planning the Reengineering of Legacy Systems}},
volume = {12},
year = {1995}
}
@article{Adzic2016,
author = {Adzic, Gojko and Evans, David and Roden, Tom},
file = {:D$\backslash$:/CIT/FYP/books/50quickideas-tests.pdf:pdf},
title = {{Fifty Quick Ideas to Improve Your Tests}},
year = {2016}
}
@article{Thatte2019,
abstract = {Data visualization has a strong design element to it. Given the differences in domains, applications and audience it's hard to put a structure around the best way to visualize your data. However, there definitely are wrong ways of doing it! I have come across multitude of such instances which were a driving force behind this post.},
author = {Thatte, Suraj},
journal = {towardsdatascience.com},
keywords = {Data Visualization},
title = {{Tips for Effective Data Visualization}},
url = {https://towardsdatascience.com/tips-for-effective-data-visualization-d4b2af91db37},
year = {2019}
}
@article{Stengel2008,
abstract = {Figures and charts are the most influential vehicles for distributing scientific information, for affecting decisions as to the acceptance or rejection of a manuscript, and for attracting the attention of the scientific community to study results. Graphical excellence is mainly defined, first, by the highest possible data density (that is, the amount of information provided per graph area); second, by a low ink-to-data ratio (the avoidance of unnecessary shading, three-dimensionality, gridlines and what is often called 'chartjunk'); and third, by clear and unequivocal labelling of axes. The researcher's essential graphical toolbox should contain histograms, bar charts (always with measures of error), box-and-whiskers plots, scatter plots and forest plots. {\textcopyright} 2008 Elsevier Ltd. All rights reserved.},
author = {Stengel, Dirk and Calori, Georgio M. and Giannoudis, Peter V.},
doi = {10.1016/j.injury.2008.01.050},
file = {:D$\backslash$:/CIT/FYP/books/j.injury.2008.01.050.pdf:pdf},
issn = {00201383},
journal = {Injury},
keywords = {Charts,Figures,Graphical data,Manuscript writing},
number = {6},
pages = {659--665},
title = {{Graphical data presentation}},
volume = {39},
year = {2008}
}
@misc{Koen2019,
author = {Koen, Semi},
booktitle = {July 19, 2019},
title = {{5 Key Principles of Software Architecture - Towards Data Science}},
url = {https://towardsdatascience.com/5-key-principles-of-software-architecture-e5379cb10fd5},
urldate = {2020-01-03},
year = {2019}
}
@article{Shah2016,
abstract = {Requirement Engineering demands a granular level of requirement specifications with key objectives, design constraints and relevant artefacts. There exist some structured approaches, but still these are not complete and do not have open formats that describe requirements of a system/project with its artefacts. This paper introduces RDS (Requirement Description Schema), an XML-based versatile specification approach for the structural representation of functional and non-functional requirements (NFR). The approach is an efficient way of managing requirement metadata and comprehensive artefacts of requirements like status, priority, version, stability, elicitation source etc. The paper comprises a case study of online examination system for validating the instances with RDS.},
author = {Shah, Tejas and Patel, Sv},
doi = {10.1016/j.procs.2016.03.083},
file = {:C$\backslash$:/Users/User/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Shah, Patel - 2016 - A Novel Approach for Specifying Functional and Non-functional Requirements Using RDS (Requirement Description Schem.pdf:pdf},
issn = {18770509},
journal = {Procedia Computer Science},
keywords = {Non-Functional Requirement,RDS,Requirement Artefacts,Requirement Description Schema,Requirement Engineering},
pages = {852--860},
publisher = {Elsevier Masson SAS},
title = {{A Novel Approach for Specifying Functional and Non-functional Requirements Using RDS (Requirement Description Schema)}},
url = {http://dx.doi.org/10.1016/j.procs.2016.03.083},
volume = {79},
year = {2016}
}
@misc{Rost2018,
abstract = {Data Visualisation can be defined as representing numbers with shapes – and no matter what these shapes look like (areas, lines, dots), they need to have a color. Sometimes colors just make the s},
author = {Rost, Lisa Charlotte},
booktitle = {Chartable},
pages = {1--8},
title = {{What to consider when choosing colors for data visualization}},
url = {https://blog.datawrapper.de/colors/},
urldate = {2020-01-01},
year = {2018}
}
@article{Barricelli2019,
abstract = {End-User Development (EUD), End-Programming (EUP) and End-User Software Engineering (EUSE) are three related research fields that study methods and techniques for empowering end users to modify and create digital artifacts. This paper presents a systematic mapping study aimed at identifying and classifying scientific literature about EUD, EUP and EUSE in the time range January 2000–May 2017. We selected 165 papers found through a manual selection of papers from specific conferences, journal special issues, and books, integrated with an automatic search on the most important digital libraries. The answer to our research question was built through a classification of the selected papers on seven dimensions: type of approach, interaction technique, phase in which the approach is adopted, application domain, target use, class of users, and type of evaluation. Our findings suggest that EUD, EUP and EUSE are active research topics not only in Human–Computer Interaction, but also in other research communities. However, little cross-fertilization exists among the three themes, as well as unifying frameworks and approaches for guiding novice designers and practitioners. Other findings highlight trends and gaps related to the analysis' dimensions, which have implications on the design of future tools and suggest open issues for further investigations.},
author = {Barricelli, Barbara Rita and Cassano, Fabio and Fogli, Daniela and Piccinno, Antonio},
doi = {10.1016/j.jss.2018.11.041},
file = {:C$\backslash$:/Users/User/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Barricelli et al. - 2019 - End-user development, end-user programming and end-user software engineering A systematic mapping study.pdf:pdf},
issn = {01641212},
journal = {Journal of Systems and Software},
keywords = {End-user development,End-user programming,End-user software engineering,Systematic mapping study},
pages = {101--137},
publisher = {Elsevier Inc.},
title = {{End-user development, end-user programming and end-user software engineering: A systematic mapping study}},
url = {https://doi.org/10.1016/j.jss.2018.11.041},
volume = {149},
year = {2019}
}
@article{Dang2017,
author = {Dang, Ngoc Hung and Hoang, Thi Viet Ha and Tran, Manh Dung},
file = {:C$\backslash$:/Users/User/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Dang, Hoang, Tran - 2017 - Impact of Cost Control on Business Efficiency of Small and Medium Sized Enterprises in Thai Binh, Vietnam.pdf:pdf},
journal = {International Finance and Banking},
number = {2},
pages = {112--127},
title = {{Impact of Cost Control on Business Efficiency of Small and Medium Sized Enterprises in Thai Binh, Vietnam.}},
url = {http://dx.doi.org/10.5296/ifb.v4i2},
volume = {4},
year = {2017}
}
@article{Glez-Pena2013,
abstract = {Web services are the de facto standard in biomedical data integration. However, there are data integration scenarios that cannot be fully covered by Web services. A number of Web databases and tools do not support Web services, and existing Web services do not cover for all possible user data demands. As a consequence,Web data scraping, one of the oldest techniques for extracting Web contents, is still in position to offer a valid and valuable service to a wide range of bioinformatics applications, ranging from simple extraction robots to online meta-servers.This article reviews existing scraping frameworks and tools, identifying their strengths and limitations in terms of extraction capabilities. The main focus is set on showing how straightforward it is today to set up a data scraping pipeline, with minimal programming effort, and answer a number of practical needs. For exemplification purposes, we introduce a biomedical data extraction scenario where the desired data sources, well-known in clinical microbiology and similar domains, do not offer programmatic interfaces yet. Moreover, we describe the operation of WhichGenes and PathJam, two bioinformatics meta-servers that use scraping as means to cope with gene set enrichment analysis.},
author = {Glez-Pe{\~{n}}a, Daniel and Louren{\c{c}}o, An{\'{a}}lia and L{\'{o}}pez-Fern{\'{a}}ndez, Hugo and Reboiro-Jato, Miguel and Fdez-Riverola, Florentino},
doi = {10.1093/bib/bbt026},
file = {:D$\backslash$:/CIT/FYP/books/bib{\_}bbt026.pdf:pdf},
issn = {14774054},
journal = {Briefings in Bioinformatics},
keywords = {Data integration,Database interfaces,Interoperability,Web scraping},
number = {5},
pages = {788--797},
title = {{Web scraping technologies in an API world}},
volume = {15},
year = {2013}
}
